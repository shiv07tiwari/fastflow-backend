{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\fastflow\\fastflowenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from services import reddit\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borikto\n"
     ]
    }
   ],
   "source": [
    "reddit_service = reddit.RedditService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = await reddit_service.search_reddit(\"Best skills to look for in ML Engineers\", post_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linguist look for ML engineers/datascientists ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1d76m1g</td>\n",
       "      <td>MLjobs</td>\n",
       "      <td>https://www.reddit.com/r/MLjobs/comments/1d76m...</td>\n",
       "      <td>8</td>\n",
       "      <td>Hello, I'm a linguist, I look for meaningful p...</td>\n",
       "      <td>2024-06-03 20:33:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the paramount skills/tools for a data...</td>\n",
       "      <td>5</td>\n",
       "      <td>1dphmko</td>\n",
       "      <td>mlops</td>\n",
       "      <td>https://www.reddit.com/r/mlops/comments/1dphmk...</td>\n",
       "      <td>5</td>\n",
       "      <td>Have an extensive amount of data engineering a...</td>\n",
       "      <td>2024-06-27 09:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[D] Best community/website to find ML engineer...</td>\n",
       "      <td>32</td>\n",
       "      <td>1cook89</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>48</td>\n",
       "      <td>I've been searching for a machine learning eng...</td>\n",
       "      <td>2024-05-10 18:08:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it common for data engineers to have profic...</td>\n",
       "      <td>25</td>\n",
       "      <td>1b2qxvx</td>\n",
       "      <td>dataengineering</td>\n",
       "      <td>https://www.reddit.com/r/dataengineering/comme...</td>\n",
       "      <td>18</td>\n",
       "      <td>I have been scrolling through the job postings...</td>\n",
       "      <td>2024-02-29 09:29:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Engineering student Proficient in ML looking f...</td>\n",
       "      <td>3</td>\n",
       "      <td>1cyo5o4</td>\n",
       "      <td>StartUpIndia</td>\n",
       "      <td>https://www.reddit.com/r/StartUpIndia/comments...</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm an engineering student from India.\\nI have...</td>\n",
       "      <td>2024-05-23 14:19:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Are you looking for an ongoing help in program...</td>\n",
       "      <td>0</td>\n",
       "      <td>1djdmf8</td>\n",
       "      <td>careerchange</td>\n",
       "      <td>https://www.reddit.com/r/careerchange/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey there - I've been working in tech for over...</td>\n",
       "      <td>2024-06-19 13:21:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[B2B] A skilled and ambitious engineer looking...</td>\n",
       "      <td>3</td>\n",
       "      <td>1awu4z5</td>\n",
       "      <td>mspjobs</td>\n",
       "      <td>https://www.reddit.com/r/mspjobs/comments/1awu...</td>\n",
       "      <td>2</td>\n",
       "      <td>Hi!\\n\\nI'm a 28-year-old engineer from Europe ...</td>\n",
       "      <td>2024-02-22 07:16:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Looking for the best laptop between $1000-$150...</td>\n",
       "      <td>3</td>\n",
       "      <td>1e7iap6</td>\n",
       "      <td>SuggestALaptop</td>\n",
       "      <td>https://www.reddit.com/r/SuggestALaptop/commen...</td>\n",
       "      <td>10</td>\n",
       "      <td>The recommendations set out by my university a...</td>\n",
       "      <td>2024-07-20 05:29:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Best search engine to look for a WI cabin</td>\n",
       "      <td>0</td>\n",
       "      <td>1bgov7r</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>https://www.reddit.com/r/wisconsin/comments/1b...</td>\n",
       "      <td>4</td>\n",
       "      <td>As the title says, whatâ€™s the best search engi...</td>\n",
       "      <td>2024-03-17 09:45:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How to get my foot in the door? Engineering an...</td>\n",
       "      <td>2</td>\n",
       "      <td>16a8hgq</td>\n",
       "      <td>oilandgasworkers</td>\n",
       "      <td>https://www.reddit.com/r/oilandgasworkers/comm...</td>\n",
       "      <td>11</td>\n",
       "      <td>I've got roughly 6 months before I head back t...</td>\n",
       "      <td>2023-09-05 05:30:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  score       id  \\\n",
       "1   Linguist look for ML engineers/datascientists ...      1  1d76m1g   \n",
       "2   What are the paramount skills/tools for a data...      5  1dphmko   \n",
       "3   [D] Best community/website to find ML engineer...     32  1cook89   \n",
       "4   Is it common for data engineers to have profic...     25  1b2qxvx   \n",
       "5   Engineering student Proficient in ML looking f...      3  1cyo5o4   \n",
       "..                                                ...    ...      ...   \n",
       "95  Are you looking for an ongoing help in program...      0  1djdmf8   \n",
       "96  [B2B] A skilled and ambitious engineer looking...      3  1awu4z5   \n",
       "97  Looking for the best laptop between $1000-$150...      3  1e7iap6   \n",
       "98          Best search engine to look for a WI cabin      0  1bgov7r   \n",
       "99  How to get my foot in the door? Engineering an...      2  16a8hgq   \n",
       "\n",
       "           subreddit                                                url  \\\n",
       "1             MLjobs  https://www.reddit.com/r/MLjobs/comments/1d76m...   \n",
       "2              mlops  https://www.reddit.com/r/mlops/comments/1dphmk...   \n",
       "3    MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "4    dataengineering  https://www.reddit.com/r/dataengineering/comme...   \n",
       "5       StartUpIndia  https://www.reddit.com/r/StartUpIndia/comments...   \n",
       "..               ...                                                ...   \n",
       "95      careerchange  https://www.reddit.com/r/careerchange/comments...   \n",
       "96           mspjobs  https://www.reddit.com/r/mspjobs/comments/1awu...   \n",
       "97    SuggestALaptop  https://www.reddit.com/r/SuggestALaptop/commen...   \n",
       "98         wisconsin  https://www.reddit.com/r/wisconsin/comments/1b...   \n",
       "99  oilandgasworkers  https://www.reddit.com/r/oilandgasworkers/comm...   \n",
       "\n",
       "    num_comments                                               body  \\\n",
       "1              8  Hello, I'm a linguist, I look for meaningful p...   \n",
       "2              5  Have an extensive amount of data engineering a...   \n",
       "3             48  I've been searching for a machine learning eng...   \n",
       "4             18  I have been scrolling through the job postings...   \n",
       "5              5  I'm an engineering student from India.\\nI have...   \n",
       "..           ...                                                ...   \n",
       "95             0  Hey there - I've been working in tech for over...   \n",
       "96             2  Hi!\\n\\nI'm a 28-year-old engineer from Europe ...   \n",
       "97            10  The recommendations set out by my university a...   \n",
       "98             4  As the title says, whatâ€™s the best search engi...   \n",
       "99            11  I've got roughly 6 months before I head back t...   \n",
       "\n",
       "                created  \n",
       "1   2024-06-03 20:33:31  \n",
       "2   2024-06-27 09:00:03  \n",
       "3   2024-05-10 18:08:16  \n",
       "4   2024-02-29 09:29:40  \n",
       "5   2024-05-23 14:19:21  \n",
       "..                  ...  \n",
       "95  2024-06-19 13:21:18  \n",
       "96  2024-02-22 07:16:22  \n",
       "97  2024-07-20 05:29:18  \n",
       "98  2024-03-17 09:45:57  \n",
       "99  2023-09-05 05:30:57  \n",
       "\n",
       "[74 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['body'].astype(bool)]\n",
    "json_documents = df.to_dict('records')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model models/aqa does not support content generation, only ['generateAnswer'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse_synthesizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSynthesizer\n\u001b[0;32m     16\u001b[0m GEMINI_API_KEY \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMINI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mGemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/aqa\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGEMINI_API_KEY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m GeminiEmbedding(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/embedding-001\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     20\u001b[0m                               api_key\u001b[38;5;241m=\u001b[39mGEMINI_API_KEY,\n\u001b[0;32m     21\u001b[0m                               title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is a document\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Settings.llm = llm\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Settings.embed_model = embed_model\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projects\\fastflow\\fastflowenv\\lib\\site-packages\\llama_index\\llms\\gemini\\base.py:145\u001b[0m, in \u001b[0;36mGemini.__init__\u001b[1;34m(self, api_key, model, temperature, max_tokens, generation_config, safety_settings, callback_manager, api_base, transport, model_name, **generate_kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_meta\u001b[38;5;241m.\u001b[39msupported_generation_methods\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerateContent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_methods:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support content generation, only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_methods\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m     )\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m max_tokens:\n\u001b[0;32m    151\u001b[0m     max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_meta\u001b[38;5;241m.\u001b[39moutput_token_limit\n",
      "\u001b[1;31mValueError\u001b[0m: Model models/aqa does not support content generation, only ['generateAnswer']."
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import JSONNodeParser\n",
    "from typing import List, Dict, Any\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "import os \n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.response_synthesizers import BaseSynthesizer\n",
    "\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-1.5-flash\", api_key=GEMINI_API_KEY)\n",
    "embed_model = GeminiEmbedding(model_name=\"models/embedding-001\", \n",
    "                              api_key=GEMINI_API_KEY,\n",
    "                              title=\"this is a document\")\n",
    "# Settings.llm = llm\n",
    "# Settings.embed_model = embed_model\n",
    "documents = [Document(text=json.dumps(doc)) for doc in json_documents]\n",
    "nodeparser = JSONNodeParser()\n",
    "nodes = nodeparser.get_nodes_from_documents(documents)\n",
    "index = VectorStoreIndex(nodes=nodes, embed_model=embed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    \"Here are some documents containing information, they could be a JSON-like paragraphs or normal paragraphs, \\n\"\n",
    "    \"interpret them as needed.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Answer the following query based on the information, do not use any prior knowledge.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "\n",
    "class RAGStringQueryEngine(CustomQueryEngine):\n",
    "    \"\"\"RAG String Query Engine.\"\"\"\n",
    "\n",
    "    retriever: BaseRetriever\n",
    "    response_synthesizer: BaseSynthesizer\n",
    "    llm: Gemini\n",
    "    qa_prompt: PromptTemplate\n",
    "\n",
    "    def custom_query(self, query_str: str):\n",
    "        nodes = self.retriever.retrieve(query_str)\n",
    "\n",
    "        context_str = \"__\\n\\n__\".join([n.node.get_content() for n in nodes])\n",
    "        response = self.llm.complete(\n",
    "            qa_prompt.format(context_str=context_str, query_str=query_str)\n",
    "        )\n",
    "\n",
    "        return dict(response = str(response), nodes = nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=20,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "query_engine = RAGStringQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    llm=llm,\n",
    "    qa_prompt=qa_prompt,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: What are most discussed topic?\n",
      "The most discussed topics are:\n",
      "\n",
      "* **Data Engineering:**  There are multiple posts asking about data engineering courses, skills needed for data engineers, and whether ML proficiency is necessary for data engineers.\n",
      "* **AI/ML:**  Many posts are about AI/ML engineering jobs, skills needed for AI/ML engineers, and how to learn AI/ML.\n",
      "* **Software Engineering:**  There are posts about niche software engineering skills in Europe and how to transition from a general full-stack developer to a more specialized role.\n",
      "* **Career Advice:**  Several posts are about career advice, including finding the best country to move to in the EU, finding a partner for a data-driven project, and transitioning to a new career path. \n",
      "* **Game Development:**  One post discusses the best game engine to learn for non-programmers. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = \"What are most discussed topic?\"\n",
    "response = query_engine.custom_query(query1)\n",
    "\n",
    "print(\"Query 1:\", query1)\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title What are the best subreddits for women looking to improve their social skills?\n",
      "score 2\n",
      "id 10gdkn3\n",
      "subreddit SubSimGPT2Interactive\n",
      "url https://www.reddit.com/r/SubSimGPT2Interactive/comments/10gdkn3/what_are_the_best_subreddits_for_women_looking_to/\n",
      "num_comments 313\n",
      "body [removed]\n",
      "created 2023-01-20 02:48:42\n",
      "title What niche software engineering skill is currently/becoming highly looked for in Europe?\n",
      "score 50\n",
      "id 19a11vk\n",
      "subreddit cscareerquestionsEU\n",
      "url https://www.reddit.com/r/cscareerquestionsEU/comments/19a11vk/what_niche_software_engineering_skill_is/\n",
      "num_comments 49\n",
      "body Hello,  \n",
      "\n",
      "\n",
      "I am a software engineer currently 2 YoE and I was thinking of making the move to Europe in 1/2 years time. I am just a general full-stack web developer with a bit of knowledge in cloud and ML, however I was wondering if it would be smarter to increase my chances of employment by becoming more specialised in an area. I find the whole space of software interesting so going down a single path is fine with me, I just am really keen to live in Europe and work. I know that AI/ML is a bit of a buzz at the moment, but is ML a highly looked for skill or are there other areas which companies seem to be looking more for at the moment?\n",
      "created 2024-01-19 02:44:17\n",
      "title Looking for AI/ML Engineer job in Abu Dhabi \n",
      "score 1\n",
      "id 1e7w00t\n",
      "subreddit abudhabi\n",
      "url https://www.reddit.com/r/abudhabi/comments/1e7w00t/looking_for_aiml_engineer_job_in_abu_dhabi/\n",
      "num_comments 0\n",
      "body Hi all,\n",
      "I have recently relocated to Abu Dhabi and looking for ai/ml data scientist roles. I have 2 years of experience in ml and would appreciate any advice or leads. Mainly worked with NLP, would prefer if the domain is in fitness/health/lifestyle/law.\n",
      "\n",
      "\n",
      "created 2024-07-20 19:16:00\n",
      "title Looking for the best data engineering course from basic to advanced\n",
      "score 24\n",
      "id 18vws8a\n",
      "subreddit dataengineering\n",
      "url https://www.reddit.com/r/dataengineering/comments/18vws8a/looking_for_the_best_data_engineering_course_from/\n",
      "num_comments 29\n",
      "body Hey,\n",
      "\n",
      "I'm on the lookout for some cool data engineering courses to level up my skills and hopefully snag a great job. Any tips or suggestions? Thanks a bunch!\n",
      "created 2024-01-01 18:59:44\n",
      "title What are the paramount skills/tools for a data engineer looking to transition into MLOps and ML engineering? \n",
      "score 4\n",
      "id 1dphmko\n",
      "subreddit mlops\n",
      "url https://www.reddit.com/r/mlops/comments/1dphmko/what_are_the_paramount_skillstools_for_a_data/\n",
      "num_comments 5\n",
      "body Have an extensive amount of data engineering and backend development with a few projects where I had to create a few service APIs for models. Looking to transition slowly but surely into MLOps and ML engineering successfully. \n",
      "\n",
      "Much thanks in advance, any ideas or brainstorming is appreciated. \n",
      "created 2024-06-27 09:00:03\n",
      "title Is it common for data engineers to have proficiency in ML?\n",
      "score 25\n",
      "id 1b2qxvx\n",
      "subreddit dataengineering\n",
      "url https://www.reddit.com/r/dataengineering/comments/1b2qxvx/is_it_common_for_data_engineers_to_have/\n",
      "num_comments 18\n",
      "body I have been scrolling through the job postings on LinkedIn, and a lot of them have been asking for knowledge of ML with some MLOps experience. \n",
      "\n",
      "In my current company, data engineers only work on ETLs with Airflow and some services in python.\n",
      "\n",
      "So I was wondering if I need to properly learn ML to be a good data engineer and maybe secure the future so to say.\n",
      "\n",
      "created 2024-02-29 09:29:40\n",
      "title Linguist look for ML engineers/datascientists to team up with.\n",
      "score 1\n",
      "id 1d76m1g\n",
      "subreddit MLjobs\n",
      "url https://www.reddit.com/r/MLjobs/comments/1d76m1g/linguist_look_for_ml_engineersdatascientists_to/\n",
      "num_comments 8\n",
      "body Hello, I'm a linguist, I look for meaningful projects to work on  with ML engineers. Languages: English/French.  \n",
      "created 2024-06-03 20:33:31\n",
      "title Looking for best country to move in EU.\n",
      "score 82\n",
      "id 19b9f3y\n",
      "subreddit cscareerquestionsEU\n",
      "url https://www.reddit.com/r/cscareerquestionsEU/comments/19b9f3y/looking_for_best_country_to_move_in_eu/\n",
      "num_comments 266\n",
      "body Iâ€™m a 28 year old developer from Greece and Iâ€™m looking to move somewhere in EU with my family because we canâ€™t have a good quality of life here and canâ€™t save enough money.\n",
      "\n",
      "We just had a child and tried to find a plan to stay here, but it does not look good!\n",
      "\n",
      "I have a bachelors degree in Computer Engineering, 4 years of working experience and am eager to learn anything Iâ€™ll need to get a better life quality. My husband has no degree but works as an IT Administrator.\n",
      "\n",
      "We are looking for a country that provides the following:\n",
      "- Good childcare and education\n",
      "- Good healthcare\n",
      "- Work life balance\n",
      "- Low crime index\n",
      "\n",
      "Right now Iâ€™m working with: (Backend Dev)\n",
      "\n",
      "- PHP\n",
      "- MySQL\n",
      "- Mongo DB\n",
      "- Amazon S3\n",
      "- PhpStorm\n",
      "\n",
      "but at my previous job I was working with: (Fullstack Dev)\n",
      "\n",
      "- Laravel\n",
      "- NodeJS\n",
      "- CSS\n",
      "- JavaScript\n",
      "- Bootstrap-Vue\n",
      "- VueJs\n",
      "- A little bit of legacy code Angular\n",
      "\n",
      "Our goal is to save money. Any ideas?\n",
      "created 2024-01-20 16:33:44\n",
      "title I'm looking for the \"easiest\" game engine to learn as a non-programmer. I've heard Godot is the best, is it true?\n",
      "score 132\n",
      "id 16lqnqq\n",
      "subreddit godot\n",
      "url https://www.reddit.com/r/godot/comments/16lqnqq/im_looking_for_the_easiest_game_engine_to_learn/\n",
      "num_comments 113\n",
      "body Hello,\n",
      "\n",
      "I'm a an artist wanting to learn how to make my own code. I'm looking for a game engine that is not too complex and is rather easy to learn. I've heard many times that Godot is the best for this, but since I'm not knowledgeable in this field I can't really decide where to go. Godot or GameMaker?\n",
      "\n",
      "Note: I have a basic knowledge of coding (if, else, variables, and so on).  \n",
      "\n",
      "created 2023-09-18 14:52:53\n",
      "title Best things to look for in BOFFs?\n",
      "score 17\n",
      "id 1dh5cu8\n",
      "subreddit sto\n",
      "url https://www.reddit.com/r/sto/comments/1dh5cu8/best_things_to_look_for_in_boffs/\n",
      "num_comments 32\n",
      "body Traits, skills, that kind of thing, whatâ€™s the recommended ones for each career ? Iâ€™m a casual player so itâ€™s just so I donâ€™t get too frustrated taking down bots or surviving against em\n",
      "created 2024-06-16 16:44:46\n",
      "title Looking to bring in AI/ML engineer to startup that's raised 180K so far. \n",
      "score 1\n",
      "id 1cnbtdw\n",
      "subreddit u_Routine-Muffin9000\n",
      "url https://www.reddit.com/r/u_Routine-Muffin9000/comments/1cnbtdw/looking_to_bring_in_aiml_engineer_to_startup/\n",
      "num_comments 0\n",
      "body Looking to bring someone in to lead the AI/ML component of the project... willing to talk compensation!\n",
      "created 2024-05-09 00:03:54\n",
      "title Experienced ML Engineer looking for opportunities to switch\n",
      "score 1\n",
      "id 1b0dvpz\n",
      "subreddit developersIndia\n",
      "url https://www.reddit.com/r/developersIndia/comments/1b0dvpz/experienced_ml_engineer_looking_for_opportunities/\n",
      "num_comments 0\n",
      "body Hi all, I'm an ML Engineer with experience developing AI solutions like a PDF to DOCX converter using OCR, a Question-and-Answer ChatBot with BERT, and an ID card detection and verification system. I've also led data engineering for big data projects, deploying ML models using Docker and optimizing for CPU servers. Looking for new opportunities, so please reach out if you have any leads. Thanks\n",
      "created 2024-02-26 15:27:22\n",
      "title Which ANZSCO code would be the best close choice for folks working as data scientists/ data analysts/ data engineers moreover anything related to data field involving ML, AI, etc?\n",
      "score 4\n",
      "id 18qpjo5\n",
      "subreddit AusVisa\n",
      "url https://www.reddit.com/r/AusVisa/comments/18qpjo5/which_anzsco_code_would_be_the_best_close_choice/\n",
      "num_comments 10\n",
      "body Your answer or opinion on this would be really helpful and greatly appreciated.\n",
      "\n",
      "Thank you!!\n",
      "created 2023-12-26 01:15:28\n",
      "title Skills Required for to become a SysAdmin OR DevOps Engineer in India?\n",
      "score 22\n",
      "id 1dmmdd9\n",
      "subreddit developersIndia\n",
      "url https://www.reddit.com/r/developersIndia/comments/1dmmdd9/skills_required_for_to_become_a_sysadmin_or/\n",
      "num_comments 14\n",
      "body I want to build skills throughout college to become a SysAdmin or a DevOps Engineer (inme se koi bhi chalega lol)... Had computers around me for my whole childhood and teenage, had unrestricted internet access which i used for good. I am a hardware enthusiast, Balls deep into home-lab stuff :P. For now, I know: \n",
      "\n",
      "* Programming Languages \n",
      "   * Python (Basics Complete, building small projects and doing leetcode by referencing docs here and there)\n",
      "   * Bash / Shell Scripting\n",
      "   * Go (Currently Learning from w3schools, go by example and referencing docs)\n",
      "* Others\n",
      "   * Linux (I daily-drive wsl and use nvim)\n",
      "   * Docker (Building dockerfiles, docker-compose, and using the \\`docker run\\` command.)\n",
      "   * Typing speed is 90-100 wpm not like it matters just felt like adding lol\n",
      "\n",
      "I know networking is a crucial one, tell me more, any basic programming languages? databases maybe? (was looking into mongo and postgres)\n",
      "\n",
      "Should i also do CCNA and RHCSA, maybe aws certifications while im at it?\n",
      "\n",
      "Pls dont bully me if i was wrong in any way or a long shot from what i was tryna say...\n",
      "created 2024-06-23 19:09:27\n",
      "title Looking for a Data Analyst/Ai Engineer/ML engineer partner in Pune\n",
      "score 1\n",
      "id 16xqftj\n",
      "subreddit pune\n",
      "url https://www.reddit.com/r/pune/comments/16xqftj/looking_for_a_data_analystai_engineerml_engineer/\n",
      "num_comments 2\n",
      "body Seeking a dynamic partner on this data-driven journey! \n",
      "Looking for an ambitious data/AI engineer in Pune to collaborate, learn, and craft a roadmap to excellence together. Let's build the future of data science and advance technologies side by side!âœ¨âœŒðŸ»\n",
      "created 2023-10-02 13:13:33\n",
      "title Looking for someone to learn skills matching with Data Engineer profile \n",
      "score 5\n",
      "id 1bibeew\n",
      "subreddit ProgrammingBuddies\n",
      "url https://www.reddit.com/r/ProgrammingBuddies/comments/1bibeew/looking_for_someone_to_learn_skills_matching_with/\n",
      "num_comments 22\n",
      "body So basically python, sql, any cloud platform azure aws gcp then head onto tableau/power bi. Then a database tool Snowflake. I'm a beginner so need to learn this skills from scratch. We can a create a discord community if yall are up for it. Need a mentor as well. \n",
      "created 2024-03-19 09:35:13\n",
      "title Best D/K/G to invest in for HE skill tickets?\n",
      "score 9\n",
      "id 1d5tbzq\n",
      "subreddit MarioKartTour\n",
      "url https://www.reddit.com/r/MarioKartTour/comments/1d5tbzq/best_dkg_to_invest_in_for_he_skill_tickets/\n",
      "num_comments 17\n",
      "body I have saved up some tickets and would like to know whats the best stuff to upgrade out of the current pool of DKG\n",
      "created 2024-06-01 23:53:48\n",
      "title [D] Best community/website to find ML engineer interested in hourly work\n",
      "score 35\n",
      "id 1cook89\n",
      "subreddit MachineLearning\n",
      "url https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/\n",
      "num_comments 48\n",
      "body I've been searching for a machine learning engineer on platforms like Upwork, but many of the candidates seem to have limited experience in building models from scratch. They often focus on integrating pre-built ML APIs rather than developing custom models tailored to specific requirements. \n",
      "\n",
      "Where is the best place to find ML engineers that can handle the entire model development process from data collection to model deployment? \n",
      "created 2024-05-10 18:08:16\n",
      "title Staff Software Engineer in Bay with 10+ YOE. Whatâ€™s the best way to learn AI/ML to maintain relevance?\n",
      "score 40\n",
      "id 18s59ra\n",
      "subreddit learnmachinelearning\n",
      "url https://www.reddit.com/r/learnmachinelearning/comments/18s59ra/staff_software_engineer_in_bay_with_10_yoe_whats/\n",
      "num_comments 17\n",
      "body As the title stated, I am a staff software engineer at a large tech company in the Bay Area. My predominant expertise is backend distributed systems.\n",
      "\n",
      "I work closely with ML and DS engineers, and I always feel out of my depth whenever specifics of our ML models are discussed. Given this and how the technological landscape is shifting so rapidly with AI, I want to do what I can to ensure I maintain relevance in my engineering career.\n",
      "\n",
      "I donâ€™t necessarily want to transition *now* away from a general backend focus to a ML or AI related role, but I want to set myself up with a deep foundational understanding so that I could easily transition if the need arises.\n",
      "\n",
      "What is this communityâ€™s opinion on structured vs. unstructured learning? I am open to courses, certifications, or post-graduate degrees. I currently have a bachelorâ€™s in CS from 10+ years ago, but my GPA was admittedly terrible, so I worry about my marketability for masterâ€™s programs.\n",
      "\n",
      "Given my current job security, my primary focus is maximizing expertise, with a secondary focus on securing future job prospects.\n",
      "created 2023-12-27 22:27:27\n",
      "title Computer Engineering Incoming Senior - Figuring out best AI/ML grad Classes to take to specialize in Natural Language Processing\n",
      "score 1\n",
      "id 1cdu2i9\n",
      "subreddit ucf\n",
      "url https://www.reddit.com/r/ucf/comments/1cdu2i9/computer_engineering_incoming_senior_figuring_out/\n",
      "num_comments 0\n",
      "body As I understand there is only one NLP Course - CAP6640. The prereq for that course is CAP5636 - Advanced AI. My plan is to take CAP5636 in the Fall and CAP6640 in the Spring alongside CAP5512 in the spring. I am looking to take one more AI/ML class in the fall but am unsure as to which one.   \n",
      "\n",
      "\n",
      "What are some good classes to take? I am considering CAP5610, Computer Vision (not sure what the course code is) and EEL5825? Anyone have any general advice, specific classes they recommend, what they cover, etc?   \n",
      "\n",
      "\n",
      "Also if anyone has any info on EEL5825 that would be appreciated, I haven't been able to find much outside of outdated course info.  \n",
      "\n",
      "\n",
      "Thanks!  \n",
      "\n",
      "created 2024-04-27 00:53:06\n"
     ]
    }
   ],
   "source": [
    "for node in response['nodes']:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['https://www.reddit.com/r/leagueoflegends/comments/k7yl34/after_months_of_work_and_no_sleep_its_finally/',\n",
       "        344],\n",
       "       ['https://www.reddit.com/r/SubSimGPT2Interactive/comments/10gdkn3/what_are_the_best_subreddits_for_women_looking_to/',\n",
       "        313],\n",
       "       ['https://www.reddit.com/r/cscareerquestionsEU/comments/19b9f3y/looking_for_best_country_to_move_in_eu/',\n",
       "        266],\n",
       "       ['https://www.reddit.com/r/ycombinator/comments/1deynl5/feel_useless_without_coding_skills_as_ml/',\n",
       "        126],\n",
       "       ['https://www.reddit.com/r/godot/comments/16lqnqq/im_looking_for_the_easiest_game_engine_to_learn/',\n",
       "        113],\n",
       "       ['https://www.reddit.com/r/womenintech/comments/1b4bqay/finally_ready_to_leave_tech_at_age_55/',\n",
       "        110],\n",
       "       ['https://www.reddit.com/r/Piracy/comments/ovwrwg/new_torrent_search_engine_in_town_bitsearchto/',\n",
       "        107],\n",
       "       ['https://www.reddit.com/r/lostarkgame/comments/w0d3dc/what_to_look_for_in_bus_drivers_minimum/',\n",
       "        98],\n",
       "       ['https://www.reddit.com/r/civilengineering/comments/p63mp4/best_states_to_work_in_for_civil_engineers/',\n",
       "        86],\n",
       "       ['https://www.reddit.com/r/learnprogramming/comments/ltngms/im_a_software_engineer_looking_for_beginners_to/',\n",
       "        75]], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='num_comments', ascending=False)[['url', 'num_comments']].head(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import services\n",
    "import services.mem_rag\n",
    "from importlib import reload\n",
    "reload(services.mem_rag)\n",
    "from services.mem_rag import InMemoryRAG\n",
    "\n",
    "rag = InMemoryRAG()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.add_documents(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 50 comments:\n",
      "\n",
      "Comment 1:\n",
      "Author: @CookwithMunu\n",
      "Text: God save this song from badsha  ðŸ™‚\n",
      "Likes: 0\n",
      "Published at: 2024-08-03T13:34:19Z\n",
      "\n",
      "Comment 2:\n",
      "Author: @Rerurusglamdust\n",
      "Text: i hate this songs\n",
      "Likes: 0\n",
      "Published at: 2024-08-02T19:17:53Z\n",
      "\n",
      "Comment 3:\n",
      "Author: @Rerurusglamdust\n",
      "Text: faltu songs\n",
      "Likes: 0\n",
      "Published at: 2024-08-02T19:17:42Z\n",
      "\n",
      "Comment 4:\n",
      "Author: @MdLatifurIslamLabib\n",
      "Text: Who listening this song in 2024 ðŸ˜…\n",
      "Likes: 0\n",
      "Published at: 2024-08-01T05:09:16Z\n",
      "\n",
      "Comment 5:\n",
      "Author: @unmeshakhajbage4165\n",
      "Text: \"Kyu\" and \"haye\"of sonu nigam has my heart \n",
      "And that \"haa\" of shreya ghosal is just awesomeâ¤â¤\n",
      "Likes: 0\n",
      "Published at: 2024-07-29T13:53:07Z\n",
      "\n",
      "... and 45 more comments.\n"
     ]
    }
   ],
   "source": [
    "from services.youtube_scraper import fetch_youtube_comments\n",
    "\n",
    "# Test the fetch_youtube_comments function\n",
    "video_id = \"SAiyopkF22M\"  # Replace with a valid YouTube video ID\n",
    "max_results = 50  # Adjust as needed\n",
    "\n",
    "comments = fetch_youtube_comments(video_id, max_results)\n",
    "\n",
    "print(f\"Fetched {len(comments)} comments:\")\n",
    "for i, comment in enumerate(comments[:5], 1):  # Print first 5 comments as a sample\n",
    "    print(f\"\\nComment {i}:\")\n",
    "    print(f\"Author: {comment['author']}\")\n",
    "    print(f\"Text: {comment['text']}\")\n",
    "    print(f\"Likes: {comment['likes']}\")\n",
    "    print(f\"Published at: {comment['published_at']}\")\n",
    "\n",
    "print(f\"\\n... and {len(comments) - 5} more comments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\nWhen authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m tweet_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1816862466816496101\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Fetch replies for the tweet\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m replies \u001b[38;5;241m=\u001b[39m \u001b[43mget_tweet_replies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweet_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replies \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(replies)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m replies to tweet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtweet_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Projects\\fastflow\\fastflow-backend\\experiments\\..\\services\\tweets.py:8\u001b[0m, in \u001b[0;36mget_tweet_replies\u001b[1;34m(tweet_id)\u001b[0m\n\u001b[0;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mClient(bearer_token\u001b[38;5;241m=\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTWITTER_BEARER_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get the conversation ID for the tweet\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m tweet \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tweet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweet_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpansions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconversation_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m conversation_id \u001b[38;5;241m=\u001b[39m tweet\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mconversation_id\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Get replies using the conversation ID\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projects\\fastflow\\fastflowenv\\lib\\site-packages\\tweepy\\client.py:1773\u001b[0m, in \u001b[0;36mClient.get_tweet\u001b[1;34m(self, id, user_auth, **params)\u001b[0m\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tweet\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mid\u001b[39m, \u001b[38;5;241m*\u001b[39m, user_auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m   1737\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"get_tweet( \\\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;124;03m        id, *, expansions=None, media_fields=None, place_fields=None, \\\u001b[39;00m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;124;03m        poll_fields=None, tweet_fields=None, user_fields=None, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1771\u001b[0m \u001b[38;5;124;03m    https://developer.twitter.com/en/docs/twitter-api/tweets/lookup/api-reference/get-tweets-id\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1774\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/2/tweets/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1776\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpansions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedia.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplace.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoll.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   1778\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTweet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\fastflow\\fastflowenv\\lib\\site-packages\\tweepy\\client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, route, params\u001b[38;5;241m=\u001b[39m{}, endpoint_parameters\u001b[38;5;241m=\u001b[39m(), json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    126\u001b[0m ):\n\u001b[0;32m    127\u001b[0m     request_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 129\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;129;01mis\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Projects\\fastflow\\fastflowenv\\lib\\site-packages\\tweepy\\client.py:100\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(response)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(response)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFound(response)\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 Forbidden\nWhen authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal."
     ]
    }
   ],
   "source": [
    "# Import the function from the tweets service\n",
    "from services.tweets import get_tweet_replies\n",
    "\n",
    "# Example tweet ID\n",
    "tweet_id = '1816862466816496101'\n",
    "\n",
    "# Fetch replies for the tweet\n",
    "replies = get_tweet_replies(tweet_id)\n",
    "\n",
    "if replies is not None:\n",
    "    print(f\"Found {len(replies)} replies to tweet {tweet_id}\")\n",
    "    for reply in replies:\n",
    "        print(f\"Reply from @{reply.user.screen_name}: {reply.full_text}\")\n",
    "else:\n",
    "    print(\"Failed to fetch replies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "    # Set up authentication using environment variables\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuth2AppHandler(\n",
    "    os.environ.get(\"TWITTER_API_KEY\"),\n",
    "    os.environ.get(\"TWITTER_API_SECRET_KEY\"),\n",
    ")\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "tweet_id = 1816892137377587684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 38\u001b[0m\n\u001b[0;32m     33\u001b[0m             data \u001b[38;5;241m=\u001b[39m xhr\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweetResult\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mscrape_tweet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://twitter.com/Scrapfly_dev/status/1664267318053179398\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m, in \u001b[0;36mscrape_tweet\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     16\u001b[0m         _xhr_calls\u001b[38;5;241m.\u001b[39mappend(response)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m async_playwright() \u001b[38;5;28;01mas\u001b[39;00m pw:\n\u001b[0;32m     20\u001b[0m     browser \u001b[38;5;241m=\u001b[39m pw\u001b[38;5;241m.\u001b[39mchromium\u001b[38;5;241m.\u001b[39mlaunch(headless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m     context \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mnew_context(viewport\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1920\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1080\u001b[39m})\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "\n",
    "def scrape_tweet(url: str) -> dict:\n",
    "    \"\"\"\n",
    "    Scrape a single tweet page for Tweet thread e.g.:\n",
    "    https://twitter.com/Scrapfly_dev/status/1667013143904567296\n",
    "    Return parent tweet, reply tweets and recommended tweets\n",
    "    \"\"\"\n",
    "    _xhr_calls = []\n",
    "\n",
    "    def intercept_response(response):\n",
    "        \"\"\"capture all background requests and save them\"\"\"\n",
    "        # we can extract details from background requests\n",
    "        if response.request.resource_type == \"xhr\":\n",
    "            _xhr_calls.append(response)\n",
    "        return response\n",
    "\n",
    "    with async_playwright() as pw:\n",
    "        browser = pw.chromium.launch(headless=False)\n",
    "        context = browser.new_context(viewport={\"width\": 1920, \"height\": 1080})\n",
    "        page = context.new_page()\n",
    "\n",
    "        # enable background request intercepting:\n",
    "        page.on(\"response\", intercept_response)\n",
    "        # go to url and wait for the page to load\n",
    "        page.goto(url)\n",
    "        page.wait_for_selector(\"[data-testid='tweet']\")\n",
    "\n",
    "        # find all tweet background requests:\n",
    "        tweet_calls = [f for f in _xhr_calls if \"TweetResultByRestId\" in f.url]\n",
    "        for xhr in tweet_calls:\n",
    "            data = xhr.json()\n",
    "            return data['data']['tweetResult']['result']\n",
    "\n",
    "\n",
    "\n",
    "print(scrape_tweet(\"https://twitter.com/Scrapfly_dev/status/1664267318053179398\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastflowenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
